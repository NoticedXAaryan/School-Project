{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef2e164-22d6-4d2c-9365-7f6a28611abf",
   "metadata": {},
   "source": [
    "<center><h1>Music & Market: Tracking Global Trends in Song Popularity and Stock Performance</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e4ff7-78e2-4d12-88f2-3236cdd0cb83",
   "metadata": {},
   "source": [
    "**Project Description :**\n",
    "<p>This project aims to explore potential connections between cultural and financial trends by comparing the most popular global songs of 2023 with stock market performance. By analyzing weekly top songs and correlating them with market data (S&P 500, NASDAQ), we hope to uncover any underlying patterns or insights that might link shifts in music tastes to economic factors.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced0b09-e9d9-49e7-9bf2-e7cba87e0ed1",
   "metadata": {},
   "source": [
    "Index (Step-by-Step Process):\n",
    "1. Project Introduction \\\n",
    "Brief introduction of the goals and scope of the project.\n",
    "\n",
    "2. Data Collection: Music Data (2023) \\\n",
    "Retrieving weekly top global songs for the year 2023 using reliable sources like Billboard.\n",
    "\n",
    "3. Data Collection: Stock Market Data (2023) \\\n",
    "Gathering weekly stock market data (S&P 500, NASDAQ) for the same year.\n",
    "\n",
    "4. Data Cleaning & Preparation \\\n",
    "Formatting and structuring the collected data for analysis.\n",
    "\n",
    "5. Data Analysis \\\n",
    "Visualizing trends and performing correlation analysis between music and stock market data.\n",
    "\n",
    "6. Conclusion and Findings \\\n",
    "Summarizing insights and drawing conclusions from the analysis.\n",
    "\n",
    "7. Website Creation \\\n",
    "Presenting findings in a dynamic, interactive website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb9b21-960b-48d7-8922-a154075092ff",
   "metadata": {},
   "source": [
    "**Step 1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d1f15f-d756-4c29-b282-68af8dd4df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'top_5_songs_2023.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Function to get the top 5 songs for a given week\n",
    "def get_top_songs_for_week(week):\n",
    "    url = f\"https://www.billboard.com/charts/hot-100/{week}/\"\n",
    "    \n",
    "    # Add headers to mimic a browser request\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP request to get the webpage content\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        \n",
    "        # Parse the page content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find the top 5 songs by locating the relevant HTML elements\n",
    "        song_titles = []\n",
    "        \n",
    "        # Get all h3 elements for the song titles\n",
    "        song_tags = soup.find_all(\"h3\", class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\")\n",
    "        \n",
    "        # Collect the first 5 song titles\n",
    "        for song_tag in song_tags[:5]:  # Limit to first 5 songs\n",
    "            song_title = song_tag.get_text(strip=True)\n",
    "            song_titles.append(song_title)\n",
    "        \n",
    "        # Fill with \"N/A\" if less than 5 songs are found\n",
    "        while len(song_titles) < 5:\n",
    "            song_titles.append(\"N/A\")\n",
    "        \n",
    "        return [week] + song_titles  # Return week and top 5 songs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for week {week}: {e}\")\n",
    "        return [week] + ['Error'] * 5  # Return error message for that week\n",
    "\n",
    "# Generate the list of weeks in 2023\n",
    "weeks_in_2023 = [\n",
    "    \"2023-01-07\", \"2023-01-14\", \"2023-01-21\", \"2023-01-28\",\n",
    "    \"2023-02-04\", \"2023-02-11\", \"2023-02-18\", \"2023-02-25\",\n",
    "    \"2023-03-04\", \"2023-03-11\", \"2023-03-18\", \"2023-03-25\",\n",
    "    \"2023-04-01\", \"2023-04-08\", \"2023-04-15\", \"2023-04-22\",\n",
    "    \"2023-04-29\", \"2023-05-06\", \"2023-05-13\", \"2023-05-20\",\n",
    "    \"2023-05-27\", \"2023-06-03\", \"2023-06-10\", \"2023-06-17\",\n",
    "    \"2023-06-24\", \"2023-07-01\", \"2023-07-08\", \"2023-07-15\",\n",
    "    \"2023-07-22\", \"2023-07-29\", \"2023-08-05\", \"2023-08-12\",\n",
    "    \"2023-08-19\", \"2023-08-26\", \"2023-09-02\", \"2023-09-09\",\n",
    "    \"2023-09-16\", \"2023-09-23\", \"2023-09-30\", \"2023-10-07\",\n",
    "    \"2023-10-14\", \"2023-10-21\", \"2023-10-28\", \"2023-11-04\",\n",
    "    \"2023-11-11\", \"2023-11-18\", \"2023-11-25\", \"2023-12-02\",\n",
    "    \"2023-12-09\", \"2023-12-16\", \"2023-12-23\", \"2023-12-30\"\n",
    "]\n",
    "\n",
    "# Prepare CSV file to save the data\n",
    "with open(\"top_5_songs_2023.csv\", mode=\"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writerow([\"Date\", \"Top 1 Song\", \"Top 2 Song\", \"Top 3 Song\", \"Top 4 Song\", \"Top 5 Song\"])\n",
    "    \n",
    "    # Fetch and write the top 5 songs for each week in 2023\n",
    "    for week in weeks_in_2023:\n",
    "        top_songs = get_top_songs_for_week(week)\n",
    "        writer.writerow(top_songs)\n",
    "\n",
    "print(\"Data has been written to 'top_5_songs_2023.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761afcd-be8b-4ed9-a4aa-70cba96b5bd7",
   "metadata": {},
   "source": [
    "**Step 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc14ab4-6a76-4942-a4e3-7846e05a130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as top_5_songs_2023_with_mood_no_neutral.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'top_5_songs_2023.csv'  # Change this to your file path\n",
    "songs_df = pd.read_csv(file_path)\n",
    "\n",
    "# Defining a simple mood dictionary for the songs\n",
    "mood_dict = {\n",
    "    \"Rockin' Around The Christmas Tree\": \"Happy\",\n",
    "    \"Jingle Bell Rock\": \"Happy\",\n",
    "    \"Last Christmas\": \"Romantic\",\n",
    "    \"A Holly Jolly Christmas\": \"Happy\",\n",
    "    \"It's The Most Wonderful Time Of The Year\": \"Happy\",\n",
    "    \"Unholy\": \"Energetic\",\n",
    "    \"Kill Bill\": \"Sad\",\n",
    "    \"Anti-Hero\": \"Sad\",\n",
    "    \"I'm Good (Blue)\": \"Energetic\",\n",
    "    \"Creepin'\": \"Sad\",\n",
    "    \"Rich Flex\": \"Energetic\",\n",
    "    \"Die For You\": \"Romantic\"\n",
    "}\n",
    "\n",
    "# Function to calculate the overall mood for a week, excluding \"Neutral\"\n",
    "def calculate_mood_no_neutral(row):\n",
    "    # Get the mood for each song, skip songs not in the dictionary\n",
    "    moods = [mood_dict.get(song) for song in row[1:] if mood_dict.get(song)]\n",
    "    if moods:  # If there are valid moods, return the most frequent mood\n",
    "        mood_counts = pd.Series(moods).value_counts()\n",
    "        return mood_counts.idxmax()\n",
    "    return \"Undefined\"  # Fallback if no valid moods\n",
    "\n",
    "# Apply the function to each row and create a new column \"Overall Mood\"\n",
    "songs_df['Overall Mood'] = songs_df.apply(calculate_mood_no_neutral, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'top_5_songs_2023_with_mood_no_neutral.csv'\n",
    "songs_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved as {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166a320-966a-4e31-bdb2-d4ebec3234a3",
   "metadata": {},
   "source": [
    "**Step 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9161a47f-7c36-45f2-bd7d-1c279f1b5bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly ACWI stock prices saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Dates for each week in 2023\n",
    "weeks_in_2023 = [\n",
    "    \"2023-01-07\", \"2023-01-14\", \"2023-01-21\", \"2023-01-28\",\n",
    "    \"2023-02-04\", \"2023-02-11\", \"2023-02-18\", \"2023-02-25\",\n",
    "    \"2023-03-04\", \"2023-03-11\", \"2023-03-18\", \"2023-03-25\",\n",
    "    \"2023-04-01\", \"2023-04-08\", \"2023-04-15\", \"2023-04-22\",\n",
    "    \"2023-04-29\", \"2023-05-06\", \"2023-05-13\", \"2023-05-20\",\n",
    "    \"2023-05-27\", \"2023-06-03\", \"2023-06-10\", \"2023-06-17\",\n",
    "    \"2023-06-24\", \"2023-07-01\", \"2023-07-08\", \"2023-07-15\",\n",
    "    \"2023-07-22\", \"2023-07-29\", \"2023-08-05\", \"2023-08-12\",\n",
    "    \"2023-08-19\", \"2023-08-26\", \"2023-09-02\", \"2023-09-09\",\n",
    "    \"2023-09-16\", \"2023-09-23\", \"2023-09-30\", \"2023-10-07\",\n",
    "    \"2023-10-14\", \"2023-10-21\", \"2023-10-28\", \"2023-11-04\",\n",
    "    \"2023-11-11\", \"2023-11-18\", \"2023-11-25\", \"2023-12-02\",\n",
    "    \"2023-12-09\", \"2023-12-16\", \"2023-12-23\", \"2023-12-30\"\n",
    "]\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each date\n",
    "for week in weeks_in_2023:\n",
    "    try:\n",
    "        # Fetch data for the specific date\n",
    "        data = yf.download(\"ACWI\", start=week, end=pd.to_datetime(week) + pd.DateOffset(7), interval=\"1d\")\n",
    "        \n",
    "        # Check if data is not empty\n",
    "        if not data.empty:\n",
    "            # Get the close price from the last day of the week\n",
    "            close_price = data['Close'].iloc[-1]  # Fetching the last available close price\n",
    "            results.append({'Date': week, 'Close Price': close_price})\n",
    "        else:\n",
    "            results.append({'Date': week, 'Close Price': None})  # No data available\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {week}: {e}\")\n",
    "        results.append({'Date': week, 'Close Price': None})  # Handle error\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save data to a CSV file\n",
    "df.to_csv('acwi_weekly_prices_2023.csv', index=False)\n",
    "\n",
    "print(\"Weekly ACWI stock prices saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac707431-f19b-42cc-9683-9acadaaa8e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
